import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import cv2
from matplotlib import pyplot as plt
import tensorflow as tf
import random
from config import Config
from dataLoader import DataLoader

from nets import *
from utils import *
os.environ['TF_CPP_MIN_LOG_LEVEL']='10'


class SfMLearner(object):
	def __init__(self, opt):
		self.opt = opt
	
	def preprocess_image(self, image):
		# Assume input image is uint8
		image = tf.image.convert_image_dtype(image, dtype = tf.float32)
		return image * 2. - 1.


	def build_train_graph(self):
		dataloader = DataLoader(self.opt.dataset_dir,
								self.opt.batch_size,
								self.opt.img_height,
								self.opt.img_width,
								self.opt.seq_length,
								self.opt.num_source,
								self.opt.num_scales)


		#file_list = dataloader.load_train_batch()

		#self.image_seqs = dataloader.load_train_batch()
		#self.image_seq, _, _ = dataloader.load_train_batch()

		# self.intrinsics : [B, S, 3, 3] (bacth * num_scales * 3 * 3)
		# self.tgt_image : [B, H, W, 3] ( batch * img_height * img_width * 3)
		# self.src_image : [B, H, W, N * 3] (batch * img_height * img_width * (num_source * 3))
		with tf.name_scope("data_loading"):
			self.intrinsics, self.tgt_image, self.src_image_stack = \
				dataloader.load_train_batch()

			self.tgt_image = self.preprocess_image(self.tgt_image)
			self.src_image_stack = self.preprocess_image(self.src_image_stack)

			"""
			print("intrinsics dimension")
			print(self.intrinsics.get_shape().as_list())
			print("tgt_image dimension")
			print(self.tgt_image.get_shape().as_list())
			print("src_image dimension")
			print(self.src_image_stack.get_shape().as_list())
			"""
		# self.pred_disp : [disp1, disp2, disp3, disp4]
		# disp1 : [B, H, W, 1], disp2 : [B, H/2, W/2, 1], disp3 : [B, H /4, W/4, 1], disp4 : [B, H / 8, W/8, 1]
		with tf.name_scope("depth_prediction"):
			self.pred_disp, self.depth_net_endpoints = disp_net(self.tgt_image,
														is_training=True)
			self.pred_depth = [(1. / disp ) for disp in self.pred_disp]
			#print(self.pred_depth)


		# self.pred_pose_avg : [B, N * 6] (batch * (num_source * 6))
		# self.pred_pose_final : [B, N, 6] (batch * num_source * 6)
		with tf.name_scope("pose_prediction"):
			self.pred_pose_avg, self.pred_pose_final, self.pred_mask, self.pose_net_endpoints = \
				pose_exp_net(self.tgt_image, self.src_image_stack, False, True)

		with tf.name_scope("compute_loss"):
			pixel_loss = 0
			smooth_loss = 0
			tgt_image_all = []
			src_image_stack_all = []
			proj_image_stack_all = []
			proj_error_stack_all = []

			for s in range(self.opt.num_scales):
				curr_tgt_image = tf.image.resize_area(self.tgt_image, 
													[int(self.opt.img_height / (2**s)), int (self.opt.img_width / (2**s))])
				curr_src_image_stack = tf.image.resize_area(self.src_image_stack, 
													[int(self.opt.img_height / (2**s)), int (self.opt.img_width / (2**s))])

				if self.opt.smooth_weight > 0:
					smooth_loss += self.opt.smooth_weight/(2**s) * \
						self.compute_smooth_loss(self.pred_disp[s])
				for i in range(self.opt.num_source):
					#print("aaaa")
					#print(i)
					# self.curr_proj_image : [B, H, W, C] (batch, height, width, channels)
					curr_proj_image = \
							proj_inverse_map(tf.slice(curr_src_image_stack, [0, 0, 0, i * 3], [-1, -1, -1, 3]), 
									 tf.squeeze(self.pred_depth[s], axis = 3),
									 tf.squeeze(tf.slice(self.pred_pose_final, [0, i, 0], [-1, 1, -1]), axis = 1),
									 #self.pred_pose_final[:, 1, :],
									 tf.squeeze(tf.slice(self.intrinsics, [0, s, 0, 0], [-1, 1, -1, -1]), axis = 1))
					#print("0000000000")
					#print(curr_proj_image)
					#print(curr_tgt_image)
					curr_proj_error = tf.abs(curr_proj_image - curr_tgt_image)
					
					pixel_loss += tf.reduce_mean(curr_proj_error)

					if i == 0:
						proj_image_stack = curr_proj_image
						proj_error_stack = curr_proj_error
					else:
						proj_image_stack = tf.concat([proj_image_stack, curr_proj_image], axis = 3)

						proj_error_stack = tf.concat([proj_error_stack, curr_proj_error], axis = 3)
				tgt_image_all.append(curr_tgt_image)
				src_image_stack_all.append(curr_src_image_stack)
				proj_image_stack_all.append(proj_image_stack)
				proj_error_stack_all.append(proj_error_stack)
			self.total_loss = pixel_loss + smooth_loss

		with tf.name_scope("train_op"):
			train_vars = [var for var in tf.trainable_variables()]
			optim = tf.train.AdamOptimizer(self.opt.learning_rate, self.opt.beta1)
			self.train_op = slim.learning.create_train_op(self.total_loss, optim)
			self.global_step = tf.Variable(0, name = 'global_step', trainable = False)
			self.incr_global_step = tf.assign(self.global_step, self.global_step+1)

		self.steps_per_epoch = dataloader.steps_per_epoch
			

	def compute_smooth_loss(self, pred_disp):
		def gradient(pred):
			D_dy = pred[:, 1:, :, :] - pred[:, :-1, :, :]
			D_dx = pred[:, :, 1:, :] - pred[:, :, :-1, :]
			return D_dx, D_dy
		dx, dy = gradient(pred_disp)
		dx2, dxdy = gradient(dx)
		dydx, dy2 = gradient(dy)
		return tf.reduce_mean(tf.abs(dx2)) + \
				tf.reduce_mean(tf.abs(dxdy)) + \
				tf.reduce_mean(tf.abs(dydx)) + \
				tf.reduce_mean(tf.abs(dy2))

	
	def train(self):
		self.build_train_graph()
		
		sv = tf.train.Supervisor(logdir=self.opt.checkpoint_dir,
								 save_summaries_secs = 0,
								 saver = None)
		config = tf.compat.v1.ConfigProto()
		config.gpu_options.allow_growth = True
		with sv.managed_session(config = config) as sess:
	
			#tf.local_variables_initializer().run()
			#sess.run(tf.global_variables_initializer())
			#threads = tf.train.start_queue_runners(sess = sess)

			"""
			print(self.intrinsics)
			print(self.intrinsics.name)
			print(self.pred_disp)
			print(self.pred_disp.name)
			"""


			# The follow code use to debug image inputs, show image dataset
			"""
			featches = {"intrinsics" : self.intrinsics,
						"tgt_image" : self.tgt_image,
						"src_image_stack" : self.src_image_stack,
						#"pro_tgt_image" : self.pro_tgt_image,
						#"auged_tgt_image" : self.auged_tgt_image
						}

			for _ in range(self.opt.max_steps):

				result = sess.run(featches)

				img1 = cv2.cvtColor(result["tgt_image"][0], cv2.COLOR_BGR2RGB)
				cv2.imshow("tg_image0", img1)

				#cv2.imshow('tgt_image0', result["tgt_image"][0])
				#cv2.imshow('pro_tgt_image0', result["pro_tgt_image"][0])
				#cv2.imshow('tgt_image1', result["tgt_image"][1])
				#cv2.imshow('tgt_image2', result["tgt_image"][2])
				#cv2.imshow('tgt_image3', result["tgt_image"][3])
				#print(result["intrinsics"][0])
				#print(result["intrinsics"][1])
				#print(result["intrinsics"][2])
				#print(result["intrinsics"][3])
				#cv2.imshow('auged_tgt_image', result["auged_tgt_image"][0])
				print("auged_tgt_image size :")
				print(len(result["auged_tgt_image"][0]))
				print(len(result["auged_tgt_image"][0][0]))
				print("raw_tgt_image size :")
				print(len(result["tgt_image"][0]))
				print(len(result["tgt_image"][0][0]))
	
				cv2.waitKey(0)

			#for _ in range(self.opt.max_steps):
			#print(depth for depth in self.pred_depth)
			#print((k, v) for k, v in self.depth_net_endpoints)
			# following code show endpoints of tensorflow 
			for depth in self.pred_depth:
				print(depth)
			for k, v in self.depth_net_endpoints.items():
				print(k, v)
			#for pose in self.pred_pose:
			for k, v in self.pose_net_endpoints.items():
				print(k, v)
			print("pose_avg ", self.pred_pose_avg)
			print("pose_final ", self.pred_pose_final)
			print('tgt_image', self.tgt_image)
			print("--------------------------------------------------------------------")
			#print(sess.run(self.translation))
			#print(self.curr_proj_image)
			print(sess.run(self.pixel_loss))

			# depth_images is a list
			# [depth1, depth2, depth3, depth4], represent different scale
			# depth1 : [B, H, W, 1]

			depth_images = sess.run(self.pred_depth)
	
			for depth_image in depth_images:
				print(len(depth_image[0]), len(depth_image[0][0]))

				cv2.imshow("depth", depth_image[0])
				cv2.waitKey(0)
				#plt.imshow(depth_image[0], 'gray')
				#plt.show()
			#plt.imshow(depth_images[0], 'gray')
			#plt.show()
			#cv2.imshow("depth", depth_image[1])
			#cv2.waitKey(0)

			"""
			#print(sess.run(self.total_loss))
			start_time = time.time()
			fetches = {	"loss" : self.total_loss,
						"train" : self.train_op,
						"global_step" : self.global_step,
						"incr_global_step" : self.incr_global_step}
			for step in range(1, self.opt.max_steps):
				results = sess.run(fetches)
				gs = results["global_step"]

				if step % self.opt.summary_freq ==0 :
					print("step: [%2d], loss:[%3f]" %(step, results['loss']))

				if step % self.steps_per_epoch == 0:
					self.save(sess, self.opt.checkpoint_dir, gs)
	
	def save(self, sess, checkpoint_dir, step):
		model_name = 'model'
		sefl.saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step = step)

					

	
		
def debug():
	# set config 
	config = Config();
	opt = config.flags.FLAGS

	# print(opt.dataset_dir)

	# set sfmlearner
	sfm = SfMLearner(opt);

	#sfm.build_train_graph()

	sfm.train()

debug()

